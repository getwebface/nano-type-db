import { DurableObject } from "cloudflare:workers";
import type { DurableObjectState } from "cloudflare:workers";
import { 
  SQLSanitizer, 
  RateLimiter, 
  InputValidator, 
  QueryTimeout,
  MemoryTracker 
} from "./lib/security";
// `node:fs` is not available in Cloudflare Workers; file-system backups
// are only performed when running in a Node environment. In Workers
// we skip file-based backups and rely on R2 or other mechanisms.

/**
 * SECURITY & ARCHITECTURE NOTES:
 * 
 * 1. SQL Injection Prevention: Raw SQL queries from clients are disabled by default.
 *    The executeSQL RPC method provides controlled read-only access for analytics.
 *    All mutations go through validated RPC methods with input sanitization.
 * 
 * 2. Efficient Broadcasting - O(1) Delta Updates: Uses action-based updates (added/modified/deleted)
 *    instead of O(N) full table diffing for scalability. Key optimizations:
 *    - INSERT operations use RETURNING * to get new row without extra SELECT
 *    - UPDATE operations use UPDATE...RETURNING * to get modified row in single query
 *    - DELETE operations fetch row before deletion (SQLite limitation - no DELETE...RETURNING)
 *    - broadcastUpdate only sends the single modified row (~1KB) not entire table (~10MB+)
 *    - Sync engine uses pagination (LIMIT/OFFSET) to avoid loading all rows at once
 *    Performance: O(1) per operation instead of O(N) where N = total database size
 * 
 * 3. Vector Search Consistency: AI embeddings are async and best-effort.
 *    If embedding fails, task exists in DB but may not be searchable until
 *    a background re-indexing job runs. For production, use Cloudflare Queues
 *    to ensure eventual consistency.
 * 
 * 4. Schema Management: Currently uses raw SQL in migrations. For better type
 *    safety, consider migrating to Drizzle ORM for schema definition.
 * 
 * 5. Hybrid State Model: Implements in-memory storage (MemoryStore) for transient
 *    data like cursors and presence that doesn't need persistence. This bypasses
 *    SQLite for maximum performance and reduces write costs.
 * 
 * 6. Local Aggregation: DebouncedWriter buffers high-frequency updates (e.g., 
 *    slider UI) and flushes to SQLite periodically, reducing write operations
 *    from 100/sec to 1/sec. Superior to Convex which charges per write.
 */

interface WebSocketMessage {
  action: "subscribe" | "query" | "mutate" | "rpc" | "ping";
  table?: string;
  sql?: string;
  method?: string; 
  payload?: any;
  updateId?: string; // For optimistic updates
}

/**
 * MemoryStore: In-memory storage for transient data that doesn't need persistence
 * Use cases: cursors, presence, temporary UI state, debounced writes
 */
class MemoryStore {
  private data: Map<string, any>;
  private expiry: Map<string, number>;
  
  constructor() {
    this.data = new Map();
    this.expiry = new Map();
  }
  
  set(key: string, value: any, ttlMs?: number): void {
    this.data.set(key, value);
    if (ttlMs) {
      this.expiry.set(key, Date.now() + ttlMs);
    }
  }
  
  get(key: string): any {
    this.cleanupExpired();
    return this.data.get(key);
  }
  
  delete(key: string): boolean {
    this.expiry.delete(key);
    return this.data.delete(key);
  }
  
  has(key: string): boolean {
    this.cleanupExpired();
    return this.data.has(key);
  }
  
  keys(): IterableIterator<string> {
    this.cleanupExpired();
    return this.data.keys();
  }
  
  clear(): void {
    this.data.clear();
    this.expiry.clear();
  }
  
  private cleanupExpired(): void {
    const now = Date.now();
    for (const [key, expiryTime] of this.expiry.entries()) {
      if (now >= expiryTime) {
        this.data.delete(key);
        this.expiry.delete(key);
      }
    }
  }
}

/**
 * DebouncedWriter: Aggregates high-frequency writes and flushes periodically
 * Use case: Slider UI updates, real-time position tracking, etc.
 */
class DebouncedWriter {
  private pending: Map<string, any>;
  private flushTimer: ReturnType<typeof setTimeout> | null;
  private flushInterval: number;
  private onFlush: (updates: Map<string, any>) => void;
  
  constructor(flushIntervalMs: number, onFlush: (updates: Map<string, any>) => void) {
    this.pending = new Map();
    this.flushTimer = null;
    this.flushInterval = flushIntervalMs;
    this.onFlush = onFlush;
  }
  
  write(key: string, value: any): void {
    this.pending.set(key, value);
    
    // Reset flush timer
    if (this.flushTimer) {
      clearTimeout(this.flushTimer);
    }
    
    this.flushTimer = setTimeout(() => this.flush(), this.flushInterval);
  }
  
  flush(): void {
    if (this.pending.size > 0) {
      const updates = new Map(this.pending);
      this.pending.clear();
      this.onFlush(updates);
    }
    
    if (this.flushTimer) {
      clearTimeout(this.flushTimer);
      this.flushTimer = null;
    }
  }
  
  destroy(): void {
    this.flush();
    if (this.flushTimer) {
      clearTimeout(this.flushTimer);
    }
  }
}

/**
 * Calculate cosine similarity between two vectors using dot product
 * Since BGE embeddings are normalized, dot product equals cosine similarity
 * Returns a value between -1 and 1 (higher = more similar)
 */
function calculateCosineSimilarity(vecA: number[], vecB: number[]): number {
  if (vecA.length !== vecB.length) {
    throw new Error('Vectors must have the same length');
  }
  
  let dotProduct = 0;
  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
  }
  
  return dotProduct;
}

// 1. Define the Manifest explicitly
// Added 'search' to actions
const ACTIONS = {
  createTask: { params: ["title"] },
  completeTask: { params: ["id"] },
  deleteTask: { params: ["id"] },
  listTasks: { params: ["limit?", "offset?"] }, // Optional pagination (default: limit=100, offset=0, max limit=1000)
  search: { params: ["query"] },
  getUsage: { params: [] },
  getAuditLog: { params: [] },
  // Memory Store actions
  setCursor: { params: ["userId", "position"] },
  getCursors: { params: [] },
  setPresence: { params: ["userId", "status"] },
  getPresence: { params: [] },
  // Raw SQL interface (read-only analytics)
  executeSQL: { params: ["sql", "readonly"] },
  // Debounced updates
  updateDebounced: { params: ["key", "value"] },
  flushDebounced: { params: [] },
  // Sync Engine monitoring
  getSyncStatus: { params: [] },
  forceSyncAll: { params: [] },
  // Semantic Reflex - Killer Feature #1
  subscribeSemantic: { params: ["topic", "description", "threshold"] },
  // Psychic Data - Killer Feature #2
  streamIntent: { params: ["text"] }
};

const MIGRATIONS = [
  {
    version: 1,
    up: (sql: any) => {
      sql.exec(`CREATE TABLE IF NOT EXISTS tasks (id INTEGER PRIMARY KEY, title TEXT, status TEXT)`);
      const count = sql.exec("SELECT count(*) as c FROM tasks").toArray()[0].c;
      if (count === 0) {
        sql.exec(`INSERT INTO tasks (title, status) VALUES ('Buy milk', 'pending'), ('Walk the dog', 'completed')`);
      }
    }
  },
  {
    version: 2,
    up: (sql: any) => {
        // Usage Metering Table
        sql.exec(`CREATE TABLE IF NOT EXISTS _usage (date TEXT PRIMARY KEY, reads INTEGER DEFAULT 0, writes INTEGER DEFAULT 0)`);
        // Audit Log for Undo/History
        sql.exec(`CREATE TABLE IF NOT EXISTS _audit_log (id INTEGER PRIMARY KEY, action TEXT, payload TEXT, timestamp TEXT)`);
    }
  },
  {
      version: 3,
      up: (sql: any) => {
          try {
              sql.exec("ALTER TABLE _usage ADD COLUMN ai_ops INTEGER DEFAULT 0");
          } catch (e) {
              // Column might already exist or table issue
              console.warn("Migration v3 warning:", e);
          }
      }
  },
  {
      version: 4,
      up: (sql: any) => {
          // Debounced state table for local aggregation
          sql.exec(`CREATE TABLE IF NOT EXISTS _debounced_state (key TEXT PRIMARY KEY, value TEXT, updated_at TEXT)`);
      }
  },
  {
      version: 5,
      up: (sql: any) => {
          // Add vector_status column to tasks table for vector consistency tracking
          // Values: 'pending' | 'indexed' | 'failed'
          try {
              sql.exec("ALTER TABLE tasks ADD COLUMN vector_status TEXT DEFAULT 'pending'");
          } catch (e) {
              // Column might already exist
              console.warn("Migration v5 warning:", e);
          }
      }
  }
];

export class NanoStore extends DurableObject {
  sql: any; 
  subscribers: Map<string, Set<WebSocket>>;
  env: Env;
  doId: string;
  ctx: DurableObjectState;
  // Hybrid State: In-memory stores for transient data
  memoryStore: MemoryStore;
  debouncedWriter: DebouncedWriter;
  // Psychic cache: Track sent IDs per WebSocket
  psychicSentCache: WeakMap<WebSocket, Set<string>>;
  // Sync Engine: Track sync status and health
  syncEngine: {
    lastSyncTime: number;
    syncErrors: number;
    totalSyncs: number;
    isHealthy: boolean;
  };
  // SECURITY: Rate limiters for RPC methods (per user)
  rateLimiters: Map<string, RateLimiter>;
  // SECURITY: Memory tracker for debounced writes
  memoryTracker: MemoryTracker;
  
  // SECURITY: Configuration constants
  private static readonly MAX_SUBSCRIBERS_PER_TABLE = 10000;
  private static readonly SEMANTIC_SUBSCRIPTION_TTL_MS = 60 * 60 * 1000; // 1 hour

  constructor(ctx: DurableObjectState, env: Env) {
    super(ctx, env);
    this.ctx = ctx;
    this.env = env;
    this.sql = ctx.storage.sql;
    this.subscribers = new Map();
    this.doId = ctx.id.toString();
    
    // Initialize Memory Store for transient data
    this.memoryStore = new MemoryStore();
    
    // Initialize Psychic cache
    this.psychicSentCache = new WeakMap();
    
    // SECURITY: Initialize rate limiters
    this.rateLimiters = new Map();
    
    // SECURITY: Initialize memory tracker (10MB limit for debounced writes)
    this.memoryTracker = new MemoryTracker(10 * 1024 * 1024);
    
    // Initialize Debounced Writer (flushes every 1 second by default)
    this.debouncedWriter = new DebouncedWriter(1000, (updates) => {
      // Flush debounced writes to SQLite
      for (const [key, value] of updates.entries()) {
        try {
          this.sql.exec(
            `INSERT OR REPLACE INTO _debounced_state (key, value, updated_at) VALUES (?, ?, datetime('now'))`,
            key, JSON.stringify(value)
          );
          // Update memory tracker
          const valueSize = JSON.stringify(value).length;
          this.memoryTracker.remove(valueSize);
        } catch (e) {
          console.error(`Failed to flush debounced write for key ${key}:`, e);
        }
      }
    });
    
    // Initialize Sync Engine status
    this.syncEngine = {
      lastSyncTime: 0,
      syncErrors: 0,
      totalSyncs: 0,
      isHealthy: true
    };
    
    this.runMigrations();
    
    // Perform initial sync to D1 after migrations
    // Note: This runs asynchronously and doesn't block construction.
    // The DO can serve requests before initial sync completes.
    // For stricter consistency, use ctx.blockConcurrencyWhile() in production.
    this.performInitialSync().catch(e => {
      console.error("[Sync Engine] Initial sync failed:", e);
    });
  }

  runMigrations() {
    this.sql.exec(`CREATE TABLE IF NOT EXISTS _migrations (version INTEGER PRIMARY KEY, applied_at TEXT)`);
    const lastMigration = this.sql.exec("SELECT max(version) as v FROM _migrations").toArray()[0];
    let currentVersion = lastMigration.v || 0;

    for (const migration of MIGRATIONS) {
      if (migration.version > currentVersion) {
        try {
          migration.up(this.sql);
          this.sql.exec("INSERT INTO _migrations (version, applied_at) VALUES (?, datetime('now'))", migration.version);
        } catch (e) {
          console.error(`Migration v${migration.version} failed:`, e);
          throw e; 
        }
      }
    }
  }

  trackUsage(type: 'reads' | 'writes' | 'ai_ops') {
      const today = new Date().toISOString().split('T')[0];
      try {
        this.sql.exec(
            `INSERT INTO _usage (date, ${type}) VALUES (?, 1) 
             ON CONFLICT(date) DO UPDATE SET ${type} = ${type} + 1`,
            today
        );
      } catch (e) {
          console.error("Usage tracking failed", e);
      }
  }

  logAction(action: string, payload: any) {
      // Log Streaming Strategy: Use Cloudflare Observability instead of filling up storage
      // This prevents storage limits by streaming logs to Cloudflare's logging infrastructure
      console.log(JSON.stringify({ 
          type: 'audit_log',
          action, 
          payload, 
          timestamp: new Date().toISOString() 
      }));
  }

  /**
   * SECURITY: Check rate limit for a specific user and method
   * Returns true if request is allowed, false if rate limit exceeded
   */
  checkRateLimit(userId: string, method: string, maxRequests: number = 100, windowMs: number = 60000): boolean {
    const key = `${userId}:${method}`;
    
    // Get or create rate limiter for this user+method combination
    if (!this.rateLimiters.has(key)) {
      this.rateLimiters.set(key, new RateLimiter(maxRequests, windowMs));
    }
    
    const limiter = this.rateLimiters.get(key)!;
    const allowed = limiter.allow(userId);
    
    // Periodically cleanup old rate limiters (every 100th request)
    if (Math.random() < 0.01) {
      this.cleanupRateLimiters();
    }
    
    return allowed;
  }

  /**
   * SECURITY: Cleanup old rate limiter entries to prevent memory leaks
   */
  cleanupRateLimiters(): void {
    for (const [key, limiter] of this.rateLimiters.entries()) {
      limiter.cleanup();
    }
  }

  /**
   * Replicate data from Durable Object to D1 read replica
   * This enables horizontal scaling for read operations while maintaining
   * write consistency in the Durable Object.
   * 
   * @param table - The table name to replicate
   * @param operation - The operation type: 'insert', 'update', or 'delete'
   * @param data - The data to replicate (for insert/update) or the ID to delete
   */
  async replicateToD1(table: string, operation: 'insert' | 'update' | 'delete', data?: any) {
    if (!this.env.READ_REPLICA) {
      console.warn("D1 READ_REPLICA not available, skipping replication");
      return;
    }

    try {
      // Add room/DO identifier to track which DO the data belongs to
      const roomId = this.doId;

      switch (operation) {
        case 'insert':
        case 'update':
          if (!data) {
            console.error("Data required for insert/update operation");
            return;
          }
          
          // For tasks table, replicate with room_id for multi-tenancy
          if (table === 'tasks') {
            await this.env.READ_REPLICA.prepare(
              `INSERT OR REPLACE INTO tasks (id, title, status, room_id, vector_status) VALUES (?, ?, ?, ?, ?)`
            ).bind(data.id, data.title, data.status, roomId, data.vector_status || 'pending').run();
          }
          break;

        case 'delete':
          if (!data || !data.id) {
            console.error("ID required for delete operation");
            return;
          }
          
          // Delete from D1 with room_id constraint for safety
          if (table === 'tasks') {
            await this.env.READ_REPLICA.prepare(
              `DELETE FROM tasks WHERE id = ? AND room_id = ?`
            ).bind(data.id, roomId).run();
          }
          break;
      }
      
      // Update sync metrics
      this.syncEngine.lastSyncTime = Date.now();
      this.syncEngine.totalSyncs++;
      this.syncEngine.isHealthy = true;
      
    } catch (e) {
      // Log but don't fail the primary operation if replication fails
      console.error(`D1 replication failed for ${operation} on ${table}:`, e);
      this.syncEngine.syncErrors++;
      this.syncEngine.isHealthy = false;
    }
  }

  /**
   * Read from D1 replica with fallback to DO SQLite
   * This provides distributed read scaling while maintaining resilience
   * 
   * SECURITY IMPROVEMENTS:
   * - Uses SQLSanitizer for safe room_id injection
   * - Validates query is read-only
   * - Properly handles parameterized queries
   * 
   * Note: Query modification is designed for simple SELECT queries.
   * Complex queries with subqueries, JOINs, or nested WHERE clauses
   * should pre-include room_id filtering to avoid modification issues.
   */
  async readFromD1(query: string, ...params: any[]): Promise<any[]> {
    // Try D1 first for distributed reads
    if (this.env.READ_REPLICA) {
      try {
        // SECURITY: Validate query is read-only
        if (!SQLSanitizer.isReadOnly(query)) {
          console.warn("Attempted non-read-only query on D1:", query);
          throw new Error("Only SELECT queries are allowed on D1");
        }
        
        // Add room_id filter to ensure data isolation
        const roomId = this.doId;
        
        // SECURITY: Use SQLSanitizer for safe query modification
        const { query: modifiedQuery, params: newParams } = 
          SQLSanitizer.injectRoomIdFilter(query, roomId, params);
        
        // Properly chain bind() calls (each bind() returns a new statement)
        let stmt = this.env.READ_REPLICA.prepare(modifiedQuery);
        for (const param of newParams) {
          stmt = stmt.bind(param);
        }
        
        const result = await stmt.all();
        return result.results || [];
      } catch (e) {
        console.warn("D1 read failed, falling back to DO SQLite:", e);
      }
    }
    
    // Fallback to DO SQLite if D1 is unavailable or fails
    this.trackUsage('reads');
    return this.sql.exec(query, ...params).toArray();
  }

  /**
   * Sync Engine: Perform initial sync from DO to D1
   * Called once when the DO starts to ensure D1 has current data
   */
  async performInitialSync(): Promise<void> {
    if (!this.env.READ_REPLICA) {
      console.log("D1 READ_REPLICA not available, skipping initial sync");
      return;
    }

    try {
      console.log(`[Sync Engine] Starting initial sync for room ${this.doId}`);
      
      // Use pagination to avoid loading all tasks at once (prevents OOM at scale)
      const BATCH_SIZE = 100;
      let offset = 0;
      let totalSynced = 0;
      
      while (true) {
        const tasks = this.sql.exec(
          `SELECT * FROM tasks LIMIT ? OFFSET ?`, 
          BATCH_SIZE, 
          offset
        ).toArray();
        
        if (tasks.length === 0) {
          break; // No more tasks to sync
        }

        // Batch sync to D1
        await this.batchSyncToD1(tasks);
        
        totalSynced += tasks.length;
        offset += BATCH_SIZE;
        
        // If we got fewer results than BATCH_SIZE, we're done
        if (tasks.length < BATCH_SIZE) {
          break;
        }
      }
      
      this.syncEngine.lastSyncTime = Date.now();
      this.syncEngine.totalSyncs++;
      this.syncEngine.isHealthy = true;
      
      console.log(`[Sync Engine] Initial sync completed: ${totalSynced} tasks synced`);
    } catch (e) {
      console.error("[Sync Engine] Initial sync failed:", e);
      this.syncEngine.syncErrors++;
      this.syncEngine.isHealthy = false;
      // Don't throw - allow DO to continue operating even if sync fails
    }
  }

  /**
   * Sync Engine: Batch sync multiple records to D1
   * More efficient than individual syncs for bulk operations
   */
  async batchSyncToD1(tasks: any[]): Promise<void> {
    if (!this.env.READ_REPLICA || tasks.length === 0) {
      return;
    }

    try {
      const roomId = this.doId;
      
      // Use D1 batch API for better performance
      const statements = tasks.map(task => 
        this.env.READ_REPLICA.prepare(
          `INSERT OR REPLACE INTO tasks (id, title, status, room_id, vector_status) VALUES (?, ?, ?, ?, ?)`
        ).bind(task.id, task.title, task.status, roomId, task.vector_status || 'pending')
      );

      // Execute all statements in a batch
      await this.env.READ_REPLICA.batch(statements);
      
      console.log(`[Sync Engine] Batch synced ${tasks.length} tasks to D1`);
    } catch (e) {
      console.error("[Sync Engine] Batch sync failed:", e);
      throw e;
    }
  }

  /**
   * Sync Engine: Get sync status and health metrics
   */
  getSyncStatus(): any {
    return {
      isHealthy: this.syncEngine.isHealthy,
      lastSyncTime: this.syncEngine.lastSyncTime,
      lastSyncAge: Date.now() - this.syncEngine.lastSyncTime,
      totalSyncs: this.syncEngine.totalSyncs,
      syncErrors: this.syncEngine.syncErrors,
      // Error rate as formatted string for display (e.g., "0.13%")
      // Returned as string for convenience in UI/logging
      errorRate: this.syncEngine.totalSyncs > 0 
        ? (this.syncEngine.syncErrors / this.syncEngine.totalSyncs * 100).toFixed(2) + '%'
        : '0%',
      replicaAvailable: !!this.env.READ_REPLICA
    };
  }

  getSchema() {
    const tables = this.sql.exec("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE '\\_%' ESCAPE '\\' AND name != 'sqlite_sequence'").toArray();
    const schema: Record<string, any[]> = {};
    for (const t of tables) {
      const columns = this.sql.exec(`PRAGMA table_info("${t.name}")`).toArray();
      schema[t.name] = columns;
    }
    return schema;
  }

  isValidTableName(tableName: string): boolean {
    // Validate table name against schema
    const schema = this.getSchema();
    return schema.hasOwnProperty(tableName);
  }

    async backupToR2() {
      try {
        // If running in Node (local dev), allow file-based backup. In the
        // Cloudflare Workers runtime there is no `fs` module, so skip.
        const runningInNode = typeof process !== "undefined" && (process as any).versions?.node;
        if (!runningInNode) {
          console.log("Backup skipped: running in Cloudflare Workers (no fs available). To enable, run locally in Node.");
          return;
        }

        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        const backupPath = `/tmp/backup-${timestamp}.db`;
        // @ts-ignore: VACUUM INTO used for local SQLite file export
        this.sql.exec(`VACUUM INTO '${backupPath}'`);
        // Lazy require to avoid bundling `fs` into worker bundle
        // eslint-disable-next-line @typescript-eslint/no-var-requires
        const fs = require('fs');
        const fileBuffer = fs.readFileSync(backupPath);

        if (this.env.BACKUP_BUCKET) {
         await this.env.BACKUP_BUCKET.put(`backup-${timestamp}.db`, fileBuffer);
         console.log(`Backup uploaded: backup-${timestamp}.db`);
        } else {
         console.log("R2 Bucket not configured, skipping upload.");
        }
        fs.unlinkSync(backupPath);
      } catch (err) {
        console.error("Backup failed:", err);
      }
    }

  async fetch(request: Request): Promise<Response> {
    const url = new URL(request.url);

    // HEALTH CHECK ENDPOINT
    if (url.pathname === "/health") {
      try {
        // Perform basic health checks
        const health = {
          status: "healthy",
          timestamp: new Date().toISOString(),
          doId: this.doId,
          syncEngine: {
            isHealthy: this.syncEngine.isHealthy,
            lastSyncTime: this.syncEngine.lastSyncTime,
            syncErrors: this.syncEngine.syncErrors,
            totalSyncs: this.syncEngine.totalSyncs,
          },
          memory: {
            debouncedWritesSize: this.memoryTracker.getCurrentSize(),
            debouncedWritesLimit: this.memoryTracker.getRemaining() + this.memoryTracker.getCurrentSize(),
            debouncedWritesRemaining: this.memoryTracker.getRemaining(),
          },
          subscribers: {
            totalTables: this.subscribers.size,
            tables: Array.from(this.subscribers.entries()).map(([table, subs]) => ({
              table,
              count: subs.size
            }))
          },
          rateLimiters: {
            activeKeys: this.rateLimiters.size
          }
        };
        
        return Response.json(health);
      } catch (e: any) {
        return Response.json({
          status: "unhealthy",
          error: e.message,
          timestamp: new Date().toISOString()
        }, { status: 500 });
      }
    }

    // QUERY ENDPOINT for global queries
    if (url.pathname === "/query") {
      this.trackUsage('reads');
      const sql = url.searchParams.get("sql");
      if (!sql) {
        return new Response("Missing sql parameter", { status: 400 });
      }
      try {
        const results = this.sql.exec(sql).toArray();
        return Response.json(results);
      } catch (e: any) {
        return Response.json({ error: e.message }, { status: 500 });
      }
    }

    // MANIFEST ENDPOINT
    if (url.pathname === "/manifest") {
      this.trackUsage('reads');
      return Response.json({
        actions: ACTIONS,
        tables: this.getSchema() 
      });
    }

    if (url.pathname === "/backup") {
        await this.backupToR2();
        return new Response("Backup completed");
    }

    // Internal endpoint to update vector status (called by queue consumer)
    if (url.pathname === "/internal/update-vector-status") {
        if (request.method !== "POST") {
            return new Response("Method not allowed", { status: 405 });
        }
        try {
            const { taskId, status, values } = await request.json() as { taskId: number, status: string, values?: number[] };
            
            // Update vector status in database
            this.sql.exec("UPDATE tasks SET vector_status = ? WHERE id = ?", status, taskId);
            this.trackUsage('ai_ops');
            console.log(`Vector status updated for task ${taskId}: ${status}`);
            
            // If indexed successfully and we have values, trigger semantic reflex
            if (status === 'indexed' && values) {
                const task = this.sql.exec("SELECT * FROM tasks WHERE id = ?", taskId).toArray()[0];
                
                // NEURAL EVENT LOOP - Semantic Reflex for queued embeddings
                for (const key of this.memoryStore.keys()) {
                    if (key.startsWith('semantic_sub:')) {
                        const subscription = this.memoryStore.get(key);
                        if (subscription && subscription.vector && subscription.socket) {
                            try {
                                const similarity = calculateCosineSimilarity(values, subscription.vector);
                                if (similarity >= subscription.threshold && subscription.socket?.readyState === 1) {
                                    subscription.socket.send(JSON.stringify({
                                        type: "semantic_match",
                                        topic: subscription.topic,
                                        similarity: similarity,
                                        row: task
                                    }));
                                    console.log(`Semantic match (queued): task ${taskId} matched "${subscription.topic}" (similarity: ${similarity.toFixed(3)})`);
                                }
                            } catch (e: any) {
                                console.error(`Semantic check failed for ${key}:`, e.message);
                            }
                        }
                    }
                }
            }
            
            return new Response("Status updated", { status: 200 });
        } catch (error: any) {
            console.error("Failed to update vector status:", error);
            return new Response(`Error: ${error.message}`, { status: 500 });
        }
    }

    if (url.pathname === "/schema") {
      this.trackUsage('reads');
      const schema = this.getSchema();
      return new Response(JSON.stringify(schema), {
        headers: { "Content-Type": "application/json" }
      });
    }

    if (url.pathname === "/connect") {
      const upgradeHeader = request.headers.get("Upgrade");
      if (!upgradeHeader || upgradeHeader !== "websocket") {
        return new Response("Expected Upgrade: websocket", { status: 426 });
      }

      try {
        // @ts-ignore: WebSocketPair is a global in Cloudflare Workers
        const webSocketPair = new WebSocketPair();
        const [client, server] = Object.values(webSocketPair) as [WebSocket, WebSocket];

        this.handleSession(server);

        return new Response(null, {
          status: 101,
          // @ts-ignore: webSocket property exists in Cloudflare ResponseInit
          webSocket: client,
        });
      } catch (error: any) {
        console.error("WebSocket upgrade failed:", error);
        return new Response(`WebSocket upgrade failed: ${error.message}`, { status: 500 });
      }
    }

    return new Response("Not found", { status: 404 });
  }

  handleSession(webSocket: WebSocket) {
    // âœ… NEW WAY: Register with the Durable Object system to use Hibernation API
    // This connects the WebSocket to the webSocketMessage(), webSocketClose(), and 
    // webSocketError() class methods defined below (lines 710, 1417, 1439)
    this.ctx.acceptWebSocket(webSocket);

    // Send reset message when DO wakes up (handleSession starts)
    // This notifies clients to re-announce their cursor/presence
    try {
      webSocket.send(JSON.stringify({ type: "reset" }));
    } catch (e) {
      console.error("Failed to send reset message:", e);
    }
  }

  // Native Cloudflare Hibernation API: Class-based WebSocket handlers
  // These allow the DO to fully sleep between messages instead of staying in memory
  async webSocketMessage(webSocket: WebSocket, message: string | ArrayBuffer) {
    try {
      const data = JSON.parse(message as string) as WebSocketMessage;

      // Handle ping/pong for heartbeat
      if (data.action === "ping") {
        try {
          webSocket.send(JSON.stringify({ type: "pong" }));
        } catch (e) {
          console.error("Failed to send pong:", e);
        }
        return;
      }

      if (data.action === "subscribe" && data.table) {
        // SECURITY: Limit number of subscribers per table to prevent DoS
        if (!this.subscribers.has(data.table)) {
          this.subscribers.set(data.table, new Set());
        }
        
        const tableSubscribers = this.subscribers.get(data.table)!;
        
        if (tableSubscribers.size >= NanoStore.MAX_SUBSCRIBERS_PER_TABLE) {
          try {
            webSocket.send(JSON.stringify({
              type: "error",
              error: `Table '${data.table}' subscription limit reached (${NanoStore.MAX_SUBSCRIBERS_PER_TABLE} max). Please try again later.`
            }));
          } catch (e) {
            console.error("Failed to send subscription limit error:", e);
          }
          return;
        }
        
        tableSubscribers.add(webSocket);
      }

      if (data.action === "query" && data.sql) {
        // SECURITY: Disable raw SQL queries from client to prevent SQL injection
        webSocket.send(JSON.stringify({ 
          type: "query_error",
          error: "Raw SQL queries are disabled for security. Please use RPC methods."
        }));
        return;
      }

      if (data.action === "rpc" || (data.action as string) === "createTask") {
            const method = data.method || data.action;
            
            // Log the attempt
            // 'reads' or 'writes' tracked inside specific blocks or generally here?
            // Let's track writes here for mutations, but we have some read RPCs now.
            
            switch (method) {
                case "createTask": {
                    try {
                        // SECURITY: Get userId from authenticated session
                        // X-User-ID is set by the edge worker (src/index.ts) AFTER successful
                        // authentication. The client cannot set this header - it's added by the
                        // worker which validates the session/API key before forwarding to DO.
                        // This ensures rate limits are per actual user, not spoofable.
                        const userId = request.headers.get("X-User-ID") || "anonymous";
                        
                        // SECURITY: Rate limit check (100 creates per minute per user)
                        if (!this.checkRateLimit(userId, "createTask", 100, 60000)) {
                            webSocket.send(JSON.stringify({ 
                                type: "mutation_error", 
                                action: "createTask",
                                error: "Rate limit exceeded. Please slow down.",
                                updateId: data.updateId
                            }));
                            break;
                        }
                        
                        this.trackUsage('writes');
                        
                        // SECURITY: Input validation using InputValidator
                        const titleRaw = data.payload?.title;
                        const title = InputValidator.sanitizeString(titleRaw, 500, true);
                        
                        this.logAction(method, data.payload);
                        
                        // 1. Insert into DB (Primary operation - must succeed)
                        // Set vector_status to 'pending' initially (will be updated to 'indexed' or 'failed')
                        const result = this.sql.exec("INSERT INTO tasks (title, status, vector_status) VALUES (?, 'pending', 'pending') RETURNING *", title).toArray();
                        const newTask = result[0];

                        // 2. Replicate to D1 for distributed reads (async, non-blocking)
                        this.ctx.waitUntil(this.replicateToD1('tasks', 'insert', newTask));

                        // 3. Generate Embedding & Store (Secondary operation - best effort)
                        // Vector Consistency: Track status in database to allow retry jobs
                        // PRODUCTION FIX: Use Cloudflare Queue for reliable AI processing with retry
                        if (newTask && this.env.EMBEDDING_QUEUE) {
                            // Push embedding job to queue (will retry on failure with exponential backoff)
                            await this.env.EMBEDDING_QUEUE.send({
                                taskId: newTask.id,
                                doId: this.doId,
                                title: title,
                                timestamp: Date.now()
                            });
                            console.log(`Embedding job queued for task ${newTask.id}`);
                        } else if (newTask && this.env.AI && this.env.VECTOR_INDEX) {
                            // FALLBACK: If no queue, use old ctx.waitUntil approach
                            // Use ctx.waitUntil for async operation without blocking the response
                            this.ctx.waitUntil((async () => {
                                try {
                                    const embeddings = await this.env.AI.run('@cf/baai/bge-base-en-v1.5', { text: [title] });
                                    const values = embeddings.data[0];
                                    if (values) {
                                        await this.env.VECTOR_INDEX.upsert([{ 
                                            id: `${this.doId}:${newTask.id}`, 
                                            values,
                                            metadata: { doId: this.doId, taskId: newTask.id } 
                                        }]);
                                        this.trackUsage('ai_ops');
                                        // Update status to 'indexed' on success
                                        this.sql.exec("UPDATE tasks SET vector_status = 'indexed' WHERE id = ?", newTask.id);
                                        console.log(`Vector indexed for task ${newTask.id}`);
                                        
                                        // NEURAL EVENT LOOP - Killer Feature #1: Semantic Reflex
                                        // Hold vector in RAM and check semantic subscriptions
                                        // Calculate Cosine Similarity (Dot Product) in V8 for instant alerts
                                        for (const key of this.memoryStore.keys()) {
                                            if (key.startsWith('semantic_sub:')) {
                                                const subscription = this.memoryStore.get(key);
                                                if (subscription && subscription.vector && subscription.socket) {
                                                    try {
                                                        // Calculate cosine similarity between task vector and subscription vector
                                                        const similarity = calculateCosineSimilarity(values, subscription.vector);
                                                        
                                                        // If similarity score exceeds threshold, send semantic match notification
                                                        if (similarity >= subscription.threshold) {
                                                            // SECURITY: Check if socket is still open and valid before sending
                                                            if (subscription.socket?.readyState === 1) { // WebSocket.OPEN
                                                                try {
                                                                    subscription.socket.send(JSON.stringify({
                                                                        type: "semantic_match",
                                                                        topic: subscription.topic,
                                                                        similarity: similarity,
                                                                        row: newTask
                                                                    }));
                                                                    console.log(`Semantic match: task ${newTask.id} matched subscription "${subscription.topic}" (similarity: ${similarity.toFixed(3)})`);
                                                                } catch (sendError: any) {
                                                                    console.error(`Failed to send semantic match notification:`, sendError);
                                                                    // Mark this subscription for cleanup if socket is dead
                                                                    if (subscription.socket.readyState !== 1) {
                                                                        this.memoryStore.delete(key);
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    } catch (e: any) {
                                                        // Don't fail the entire operation if one subscription check fails
                                                        console.error(`Semantic subscription check failed for ${key}:`, e.message);
                                                    }
                                                }
                                            }
                                        }
                                    }
                                } catch (e: any) {
                                    // Update status to 'failed' on error (allows future retry)
                                    this.sql.exec("UPDATE tasks SET vector_status = 'failed' WHERE id = ?", newTask.id);
                                    console.error(`AI Embedding failed for task ${newTask.id}:`, e.message);
                                }
                            })());
                        }

                        webSocket.send(JSON.stringify({ 
                            type: "mutation_success", 
                            action: "createTask",
                            updateId: data.updateId
                        }));
                        
                        // Efficient broadcast - only send the new row
                        this.broadcastUpdate("tasks", "added", newTask);
                    } catch (e: any) {
                        webSocket.send(JSON.stringify({ 
                            type: "mutation_error", 
                            action: "createTask",
                            error: e.message,
                            updateId: data.updateId
                        }));
                    }
                    break;
                }

                case "completeTask":
                    try {
                        this.trackUsage('writes');
                        
                        // Input validation
                        const completeId = data.payload?.id;
                        if (!completeId || typeof completeId !== 'number' || !Number.isInteger(completeId) || completeId < 1) {
                            throw new Error('Invalid id: must be a positive integer');
                        }
                        
                        this.logAction(method, data.payload);
                        
                        // Use RETURNING * to get updated row in a single query (O(1) vs O(N))
                        const updated = this.sql.exec("UPDATE tasks SET status = 'completed' WHERE id = ? RETURNING *", completeId).toArray()[0];
                        
                        // Replicate to D1 for distributed reads (async, non-blocking)
                        if (updated) {
                            this.ctx.waitUntil(this.replicateToD1('tasks', 'update', updated));
                        }
                        
                        webSocket.send(JSON.stringify({ 
                            type: "mutation_success", 
                            action: "completeTask",
                            updateId: data.updateId
                        }));
                        
                        // Efficient broadcast - only send the modified row
                        if (updated) {
                            this.broadcastUpdate("tasks", "modified", updated);
                        }
                    } catch (e: any) {
                        webSocket.send(JSON.stringify({ 
                            type: "mutation_error", 
                            action: "completeTask",
                            error: e.message,
                            updateId: data.updateId
                        }));
                    }
                    break;

                case "deleteTask":
                    try {
                        this.trackUsage('writes');
                        
                        // Input validation
                        const deleteId = data.payload?.id;
                        if (!deleteId || typeof deleteId !== 'number' || !Number.isInteger(deleteId) || deleteId < 1) {
                            throw new Error('Invalid id: must be a positive integer');
                        }
                        
                        this.logAction(method, data.payload);
                        
                        // Fetch row before deleting for broadcast (SQLite doesn't support DELETE...RETURNING)
                        // This is a targeted O(1) query by primary key, not a full table scan
                        const deleted = this.sql.exec("SELECT * FROM tasks WHERE id = ?", deleteId).toArray()[0];
                        
                        this.sql.exec("DELETE FROM tasks WHERE id = ?", deleteId);
                        
                        // Replicate deletion to D1 (async, non-blocking)
                        if (deleted) {
                            this.ctx.waitUntil(this.replicateToD1('tasks', 'delete', { id: deleteId }));
                        }
                        
                        // Also delete from Vector Index
                        if (this.env.VECTOR_INDEX) {
                            this.env.VECTOR_INDEX.deleteByIds([`${this.doId}:${deleteId}`]).catch(console.error);
                        }
                        webSocket.send(JSON.stringify({ 
                            type: "mutation_success", 
                            action: "deleteTask",
                            updateId: data.updateId
                        }));
                        
                        // Efficient broadcast - only send the deleted row
                        if (deleted) {
                            this.broadcastUpdate("tasks", "deleted", deleted);
                        }
                    } catch (e: any) {
                        webSocket.send(JSON.stringify({ 
                            type: "mutation_error", 
                            action: "deleteTask",
                            error: e.message,
                            updateId: data.updateId
                        }));
                    }
                    break;
                
                case "search": {
                    this.trackUsage('ai_ops'); // It's an AI op
                    const query = data.payload?.query;
                    
                    // Input validation
                    if (!query || typeof query !== 'string') {
                        webSocket.send(JSON.stringify({ type: "query_result", data: [], originalSql: "search" }));
                        break;
                    }
                    if (query.length > 500) {
                        webSocket.send(JSON.stringify({ 
                            type: "query_error",
                            error: "Search query too long: maximum 500 characters"
                        }));
                        break;
                    }
                    
                    let results: any[] = [];
                    if (this.env.AI && this.env.VECTOR_INDEX) {
                         const embeddings = await this.env.AI.run('@cf/baai/bge-base-en-v1.5', { text: [query] });
                         const values = embeddings.data[0];
                         // Query vectors
                         const matches = await this.env.VECTOR_INDEX.query(values, { topK: 5 });
                         
                         // Filter matches for this DO
                         const taskIds = matches.matches
                            .filter(m => m.id.startsWith(this.doId))
                            .map(m => m.id.split(':')[1]); // Extract taskId
                         
                         if (taskIds.length > 0) {
                             // Safe parameterized query construction:
                             // taskIds is an internal array of integers (not user input)
                             // Each taskId maps to a '?' placeholder, preventing injection
                             const placeholders = taskIds.map(() => '?').join(',');
                             results = await this.readFromD1(`SELECT * FROM tasks WHERE id IN (${placeholders})`, ...taskIds);
                         }
                    }
                    
                    webSocket.send(JSON.stringify({ type: "query_result", data: results, originalSql: "search" }));
                    break;
                }

                case "streamIntent": {
                    // Psychic Data: Predict user needs and pre-push data
                    const text = data.payload?.text;
                    if (!text || typeof text !== 'string') {
                        break;
                    }
                    
                    try {
                        // Step 1: Generate embedding for the intent text
                        if (!this.env.AI || !this.env.VECTOR_INDEX) {
                            console.warn('AI or VECTOR_INDEX not available for streamIntent');
                            break;
                        }
                        
                        const embeddings = await this.env.AI.run('@cf/baai/bge-base-en-v1.5', { text: [text] });
                        const values = embeddings.data[0];
                        
                        if (!values) {
                            break;
                        }
                        
                        // Step 2: Query vector index for top 3 matches
                        const matches = await this.env.VECTOR_INDEX.query(values, { topK: 3 });
                        
                        // Step 3: Extract IDs from matches for this DO
                        // Validate ID format: must be "doId:taskId" with exactly one colon
                        const taskIds = matches.matches
                            .filter(m => {
                                if (!m.id.startsWith(this.doId) || !m.id.includes(':')) {
                                    return false;
                                }
                                const parts = m.id.split(':');
                                // Ensure exactly 2 parts and second part is a valid number
                                return parts.length === 2 && /^\d+$/.test(parts[1]);
                            })
                            .map(m => m.id.split(':')[1]); // Safe to split after validation
                        
                        if (taskIds.length === 0) {
                            break;
                        }
                        
                        // Step 4: Check sentCache to avoid duplicate pushes
                        // Use WeakMap with WebSocket as key
                        let sentCache = this.psychicSentCache.get(webSocket);
                        if (!sentCache) {
                            sentCache = new Set<string>();
                            this.psychicSentCache.set(webSocket, sentCache);
                        }
                        
                        // Filter out already-sent IDs
                        const newTaskIds = taskIds.filter(id => !sentCache.has(id));
                        
                        if (newTaskIds.length === 0) {
                            break; // All matches already sent
                        }
                        
                        // Step 5: Fetch full records from SQLite (primary source)
                        // Validate that all IDs are numeric before query construction
                        const validTaskIds = newTaskIds.filter(id => /^\d+$/.test(id));
                        if (validTaskIds.length === 0) {
                            break;
                        }
                        
                        // Use explicit column selection for security
                        const placeholders = validTaskIds.map(() => '?').join(',');
                        const records = this.sql.exec(
                            `SELECT id, title, status FROM tasks WHERE id IN (${placeholders})`,
                            ...validTaskIds
                        ).toArray();
                        
                        // Step 6: Push data to client silently (no state update on client)
                        if (records.length > 0) {
                            webSocket.send(JSON.stringify({
                                type: 'psychic_push',
                                data: records
                            }));
                            
                            // Mark these IDs as sent
                            validTaskIds.forEach(id => sentCache!.add(id));
                            
                            console.log(`ðŸ”® Psychic push: ${records.length} records for intent "${text}"`);
                        }
                    } catch (e: any) {
                        console.error('streamIntent error:', e.message);
                    }
                    break;
                }

                case "getUsage":
                    this.trackUsage('reads');
                    const usage = this.sql.exec("SELECT * FROM _usage ORDER BY date DESC LIMIT 30").toArray();
                    webSocket.send(JSON.stringify({ type: "query_result", data: usage, originalSql: "getUsage" }));
                    break;

                case "getAuditLog":
                     this.trackUsage('reads');
                     // Audit logs are now streamed to Cloudflare Observability via console.log
                     // Return empty array with info message
                     webSocket.send(JSON.stringify({ 
                         type: "query_result", 
                         data: [], 
                         originalSql: "getAuditLog",
                         info: "Audit logs are now streamed to Cloudflare Observability. Use Cloudflare Dashboard to view logs."
                     }));
                     break;

                case "listTasks": {
                     // Read from D1 replica for horizontal scaling
                     // Support pagination to avoid loading large datasets (max 1000 per page)
                     const limitRaw = data.payload?.limit;
                     const offsetRaw = data.payload?.offset;
                     
                     // Parse and validate pagination parameters (could be strings from payload)
                     const limit = limitRaw ? parseInt(String(limitRaw), 10) : 100; // Default 100 rows
                     const offset = offsetRaw ? parseInt(String(offsetRaw), 10) : 0;
                     
                     // Validate pagination parameters
                     const safeLimit = Math.min(Math.max(1, limit), 1000); // Between 1-1000
                     const safeOffset = Math.max(0, offset); // Non-negative
                     
                     const tasks = await this.readFromD1(
                         "SELECT * FROM tasks ORDER BY id LIMIT ? OFFSET ?", 
                         safeLimit, 
                         safeOffset
                     );
                     webSocket.send(JSON.stringify({ 
                         type: "query_result", 
                         data: tasks, 
                         originalSql: "listTasks",
                         pagination: { limit: safeLimit, offset: safeOffset }
                     }));
                     break;
                }

                // Memory Store: Cursor tracking
                case "setCursor": {
                    const { userId, position } = data.payload || {};
                    if (!userId || !position) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: "setCursor requires userId and position" 
                        }));
                        break;
                    }
                    
                    // Store cursor in memory with 30 second TTL
                    this.memoryStore.set(`cursor:${userId}`, position, 30000);
                    
                    // Broadcast cursor update to subscribers
                    this.broadcastMemoryUpdate("cursors", { userId, position });
                    
                    webSocket.send(JSON.stringify({ 
                        type: "success", 
                        action: "setCursor" 
                    }));
                    break;
                }
                
                case "getCursors": {
                    const cursors: any[] = [];
                    for (const key of this.memoryStore.keys()) {
                        if (key.startsWith('cursor:')) {
                            const userId = key.replace('cursor:', '');
                            const position = this.memoryStore.get(key);
                            cursors.push({ userId, position });
                        }
                    }
                    webSocket.send(JSON.stringify({ 
                        type: "query_result", 
                        data: cursors, 
                        originalSql: "getCursors" 
                    }));
                    break;
                }
                
                // Memory Store: Presence tracking
                case "setPresence": {
                    const { userId, status } = data.payload || {};
                    if (!userId || !status) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: "setPresence requires userId and status" 
                        }));
                        break;
                    }
                    
                    // Store presence in memory with 60 second TTL
                    this.memoryStore.set(`presence:${userId}`, status, 60000);
                    
                    // Broadcast presence update to subscribers
                    this.broadcastMemoryUpdate("presence", { userId, status });
                    
                    webSocket.send(JSON.stringify({ 
                        type: "success", 
                        action: "setPresence" 
                    }));
                    break;
                }
                
                case "getPresence": {
                    const presence: any[] = [];
                    for (const key of this.memoryStore.keys()) {
                        if (key.startsWith('presence:')) {
                            const userId = key.replace('presence:', '');
                            const status = this.memoryStore.get(key);
                            presence.push({ userId, status });
                        }
                    }
                    webSocket.send(JSON.stringify({ 
                        type: "query_result", 
                        data: presence, 
                        originalSql: "getPresence" 
                    }));
                    break;
                }
                
                // Semantic Reflex - Killer Feature #1: Subscribe based on meaning, not just ID
                case "subscribeSemantic": {
                    this.trackUsage('ai_ops'); // Track AI operation usage
                    
                    const { topic, description, threshold } = data.payload || {};
                    
                    // Input validation
                    if (!topic || typeof topic !== 'string' || topic.trim().length === 0) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: "subscribeSemantic requires a non-empty topic string" 
                        }));
                        break;
                    }
                    if (!description || typeof description !== 'string' || description.trim().length === 0) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: "subscribeSemantic requires a non-empty description string" 
                        }));
                        break;
                    }
                    if (typeof threshold !== 'number' || threshold < 0 || threshold > 1) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: "subscribeSemantic requires threshold between 0 and 1" 
                        }));
                        break;
                    }
                    
                    // Validate description length
                    if (description.length > 500) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: "Description too long: maximum 500 characters" 
                        }));
                        break;
                    }
                    
                    // Generate embedding for the subscription description
                    try {
                        if (!this.env.AI) {
                            webSocket.send(JSON.stringify({ 
                                type: "error", 
                                error: "AI service not available" 
                            }));
                            break;
                        }
                        
                        const embeddings = await this.env.AI.run('@cf/baai/bge-base-en-v1.5', { 
                            text: [description.trim()] 
                        });
                        const vector = embeddings.data[0];
                        
                        if (!vector || !Array.isArray(vector)) {
                            throw new Error('Failed to generate embedding vector');
                        }
                        
                        // SECURITY: Store subscription with TTL to prevent memory leaks
                        // Key format: semantic_sub:{topic}:{timestamp}
                        const subKey = `semantic_sub:${topic}:${Date.now()}`;
                        
                        this.memoryStore.set(subKey, {
                            topic,
                            description,
                            vector,
                            threshold,
                            socket: webSocket // Store socket reference for notifications
                        }, NanoStore.SEMANTIC_SUBSCRIPTION_TTL_MS); // Add TTL to automatically cleanup old subscriptions
                        
                        webSocket.send(JSON.stringify({ 
                            type: "success", 
                            action: "subscribeSemantic",
                            data: { topic, threshold }
                        }));
                    } catch (e: any) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: `subscribeSemantic failed: ${e.message}` 
                        }));
                    }
                    break;
                }
                
                // Full SQL Power: Safe raw SQL interface
                case "executeSQL": {
                    this.trackUsage('reads');
                    
                    const { sql: rawSql, readonly = true } = data.payload || {};
                    
                    if (!rawSql || typeof rawSql !== 'string') {
                        webSocket.send(JSON.stringify({ 
                            type: "query_error", 
                            error: "executeSQL requires sql parameter" 
                        }));
                        break;
                    }
                    
                    // SECURITY: Rate limiting for executeSQL (50 queries per minute)
                    const userId = request.headers.get("X-User-ID") || "anonymous";
                    if (!this.checkRateLimit(userId, "executeSQL", 50, 60000)) {
                        webSocket.send(JSON.stringify({ 
                            type: "query_error", 
                            error: "Rate limit exceeded for executeSQL" 
                        }));
                        break;
                    }
                    
                    // Security: Only allow read-only queries
                    if (readonly) {
                        const sqlLower = rawSql.toLowerCase().trim();
                        if (!sqlLower.startsWith('select') && !sqlLower.startsWith('with')) {
                            webSocket.send(JSON.stringify({ 
                                type: "query_error", 
                                error: "Only SELECT and WITH queries allowed in read-only mode" 
                            }));
                            break;
                        }
                    }
                    
                    // Query length limit: max 10,000 characters
                    if (rawSql.length > 10000) {
                        webSocket.send(JSON.stringify({ 
                            type: "query_error", 
                            error: "Query too long: maximum 10,000 characters" 
                        }));
                        break;
                    }
                    
                    try {
                        // PERFORMANCE: Add query timeout (5 seconds max)
                        const results = await QueryTimeout.withTimeout(
                            async () => this.readFromD1(rawSql),
                            5000,
                            "Query execution timeout (max 5 seconds)"
                        );
                        
                        webSocket.send(JSON.stringify({ 
                            type: "query_result", 
                            data: results, 
                            originalSql: rawSql 
                        }));
                    } catch (e: any) {
                        webSocket.send(JSON.stringify({ 
                            type: "query_error", 
                            error: e.message 
                        }));
                    }
                    break;
                }
                
                // Local Aggregation: Debounced writes
                case "updateDebounced": {
                    const { key, value } = data.payload || {};
                    
                    if (!key) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: "updateDebounced requires key parameter" 
                        }));
                        break;
                    }
                    
                    // SECURITY: Validate value size (max 100KB per value)
                    const valueStr = JSON.stringify(value);
                    const valueSize = valueStr.length;
                    
                    if (valueSize > 100000) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: "Value too large: maximum 100KB" 
                        }));
                        break;
                    }
                    
                    // SECURITY: Check total memory limit before accepting write
                    if (!this.memoryTracker.canAdd(valueSize)) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            error: "Memory limit reached. Please wait for pending writes to flush." 
                        }));
                        break;
                    }
                    
                    // Add to memory tracker
                    this.memoryTracker.add(valueSize);
                    
                    // Write to debounced buffer (will flush after 1 second of inactivity)
                    this.debouncedWriter.write(key, value);
                    
                    webSocket.send(JSON.stringify({ 
                        type: "success", 
                        action: "updateDebounced",
                        message: "Update queued for flush" 
                    }));
                    break;
                }
                
                case "flushDebounced": {
                    // Force immediate flush of debounced writes
                    this.debouncedWriter.flush();
                    
                    webSocket.send(JSON.stringify({ 
                        type: "success", 
                        action: "flushDebounced",
                        message: "Debounced writes flushed to SQLite" 
                    }));
                    break;
                }
                
                // Sync Engine: Get sync status and health
                case "getSyncStatus": {
                    const status = this.getSyncStatus();
                    webSocket.send(JSON.stringify({ 
                        type: "query_result", 
                        data: [status], 
                        originalSql: "getSyncStatus" 
                    }));
                    break;
                }
                
                // Sync Engine: Force full sync to D1
                case "forceSyncAll": {
                    try {
                        await this.performInitialSync();
                        webSocket.send(JSON.stringify({ 
                            type: "success", 
                            action: "forceSyncAll",
                            message: "Full sync to D1 completed",
                            status: this.getSyncStatus()
                        }));
                    } catch (e: any) {
                        webSocket.send(JSON.stringify({ 
                            type: "error", 
                            action: "forceSyncAll",
                            error: e.message 
                        }));
                    }
                    break;
                }

                default:
                    webSocket.send(JSON.stringify({ error: `Unknown RPC method: ${method}` }));
            }
        }
      
      if (data.action === "mutate") {
           webSocket.send(JSON.stringify({ error: "Raw mutations are disabled. Use RPC actions." }));
      }

    } catch (err: any) {
      console.error("WebSocket message error:", err);
      try {
        webSocket.send(JSON.stringify({ error: err.message }));
      } catch (sendError) {
        console.error("Failed to send error message:", sendError);
      }
    }
  }

  webSocketClose(webSocket: WebSocket, code: number, reason: string, wasClean: boolean) {
    console.log("WebSocket closed:", code, reason);
    this.subscribers.forEach((set) => set.delete(webSocket));
    
    // Cleanup semantic subscriptions for this WebSocket to prevent memory leaks
    const keysToDelete: string[] = [];
    for (const key of this.memoryStore.keys()) {
      if (key.startsWith('semantic_sub:')) {
        const subscription = this.memoryStore.get(key);
        if (subscription && subscription.socket === webSocket) {
          keysToDelete.push(key);
        }
      }
    }
    
    // Delete the subscriptions
    keysToDelete.forEach(key => {
      this.memoryStore.delete(key);
      console.log(`Cleaned up semantic subscription: ${key}`);
    });
  }

  webSocketError(webSocket: WebSocket, error: unknown) {
    console.error("WebSocket error:", error);
    this.subscribers.forEach((set) => set.delete(webSocket));
  }

  getPrimaryKey(tableName: string): string {
    // Validate table name first
    if (!this.isValidTableName(tableName)) {
      console.warn(`Invalid table name: ${tableName}`);
      return 'id';
    }
    
    // Get primary key column from table schema
    try {
      const columns = this.sql.exec(`PRAGMA table_info("${tableName}")`).toArray();
      const pkColumn = columns.find((col: any) => col.pk === 1);
      return pkColumn ? pkColumn.name : 'id'; // Default to 'id' if no PK found
    } catch (e) {
      console.warn(`Failed to get primary key for ${tableName}, defaulting to 'id'`);
      return 'id';
    }
  }

  broadcastUpdate(table: string, action: 'added' | 'modified' | 'deleted', row: any) {
    // Validate table name to prevent SQL injection
    if (!this.isValidTableName(table)) {
      console.error(`Invalid table name for broadcast: ${table}`);
      return;
    }
    
    if (this.subscribers.has(table)) {
      const sockets = this.subscribers.get(table)!;
      
      // Send efficient action-based update instead of full table diff
      const message = JSON.stringify({ 
        event: "update", 
        table,
        action,
        row
      });
      
      for (const socket of sockets) {
        try {
          socket.send(message);
        } catch (err) {
          sockets.delete(socket);
        }
      }
    }
  }

  broadcastMemoryUpdate(type: string, data: any) {
    // Broadcast memory store updates (cursors, presence) to all connections
    // These are ephemeral and don't need table validation
    const message = JSON.stringify({ 
      event: "memory_update", 
      type,
      data
    });
    
    // Broadcast to all subscribers regardless of table
    this.subscribers.forEach((sockets) => {
      for (const socket of sockets) {
        try {
          socket.send(message);
        } catch (err) {
          sockets.delete(socket);
        }
      }
    });
  }
}
